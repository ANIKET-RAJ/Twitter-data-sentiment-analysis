{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIKET RAJ\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          0           1                             2         3  \\\n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6        0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7        0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8        0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9        0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "10       0  1467812416  Mon Apr 06 22:20:16 PDT 2009  NO_QUERY   \n",
       "11       0  1467812579  Mon Apr 06 22:20:17 PDT 2009  NO_QUERY   \n",
       "12       0  1467812723  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "13       0  1467812771  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "14       0  1467812784  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "15       0  1467812799  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "16       0  1467812964  Mon Apr 06 22:20:22 PDT 2009  NO_QUERY   \n",
       "17       0  1467813137  Mon Apr 06 22:20:25 PDT 2009  NO_QUERY   \n",
       "18       0  1467813579  Mon Apr 06 22:20:31 PDT 2009  NO_QUERY   \n",
       "19       0  1467813782  Mon Apr 06 22:20:34 PDT 2009  NO_QUERY   \n",
       "20       0  1467813985  Mon Apr 06 22:20:37 PDT 2009  NO_QUERY   \n",
       "21       0  1467813992  Mon Apr 06 22:20:38 PDT 2009  NO_QUERY   \n",
       "22       0  1467814119  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "23       0  1467814180  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "24       0  1467814192  Mon Apr 06 22:20:41 PDT 2009  NO_QUERY   \n",
       "25       0  1467814438  Mon Apr 06 22:20:44 PDT 2009  NO_QUERY   \n",
       "26       0  1467814783  Mon Apr 06 22:20:50 PDT 2009  NO_QUERY   \n",
       "27       0  1467814883  Mon Apr 06 22:20:52 PDT 2009  NO_QUERY   \n",
       "28       0  1467815199  Mon Apr 06 22:20:56 PDT 2009  NO_QUERY   \n",
       "29       0  1467815753  Mon Apr 06 22:21:04 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599970  4  2193578196  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599971  4  2193578237  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599972  4  2193578269  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
       "1599973  4  2193578319  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599974  4  2193578345  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599975  4  2193578347  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599976  4  2193578348  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599977  4  2193578386  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599978  4  2193578395  Tue Jun 16 08:38:55 PDT 2009  NO_QUERY   \n",
       "1599979  4  2193578576  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599980  4  2193578679  Tue Jun 16 08:38:56 PDT 2009  NO_QUERY   \n",
       "1599981  4  2193578716  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599982  4  2193578739  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599983  4  2193578758  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599984  4  2193578847  Tue Jun 16 08:38:57 PDT 2009  NO_QUERY   \n",
       "1599985  4  2193578982  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599986  4  2193579087  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599987  4  2193579092  Tue Jun 16 08:38:58 PDT 2009  NO_QUERY   \n",
       "1599988  4  2193579191  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599989  4  2193579211  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599990  4  2193579249  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599991  4  2193579284  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599992  4  2193579434  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599993  4  2193579477  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599994  4  2193579489  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       4                                                  5  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5               joy_wolf                      @Kwesidei not the whole crew   \n",
       "6                mybirch                                        Need a hug   \n",
       "7                   coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8        2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9                mimismo                          @twittera que me muera ?   \n",
       "10        erinx3leannexo        spring break in plain city... it's snowing   \n",
       "11          pardonlauren                         I just re-pierced my ears   \n",
       "12                  TLeC  @caregiving I couldn't bear to watch it.  And ...  \n",
       "13       robrobbierobert  @octolinz16 It it counts, idk why I did either...  \n",
       "14           bayofwolves  @smarrison i would've been the first, but i di...  \n",
       "15            HairByJess  @iamjazzyfizzle I wish I got to watch it with ...  \n",
       "16        lovesongwriter  Hollis' death scene will hurt me severely to w...  \n",
       "17              armotley                               about to file taxes   \n",
       "18            starkissed  @LettyA ahh ive always wanted to see rent  lov...  \n",
       "19             gi_gi_bee  @FakerPattyPattz Oh dear. Were you drinking ou...  \n",
       "20                quanvu  @alydesigns i was out most of the day so didn'...  \n",
       "21            swinspeedx  one of my friend called me, and asked to meet ...  \n",
       "22             cooliodoc   @angry_barista I baked you a cake but I ated it   \n",
       "23            viJILLante             this week is not going as i had hoped   \n",
       "24            Ljelli3166                         blagh class at 8 tomorrow   \n",
       "25         ChicagoCubbie     I hate when I have to call and wake people up   \n",
       "26           KatieAngell  Just going to cry myself to sleep after watchi...  \n",
       "27                 gagoo                             im sad now  Miss.Lilly  \n",
       "28               abel209  ooooh.... LOL  that leslie.... and ok I won't ...  \n",
       "29       BaptisteTheFool  Meh... Almost Lover is the exception... this t...  \n",
       "...                  ...                                                ...  \n",
       "1599970    adbillingsley  Thanks @eastwestchic &amp; @wangyip Thanks! Th...  \n",
       "1599971           gekkko  @marttn thanks Martin. not the most imaginativ...  \n",
       "1599972       millerslab          @MikeJonesPhoto Congrats Mike  Way to go!  \n",
       "1599973  luckygeorgeblog  http://twitpic.com/7jp4n - OMG! Office Space.....  \n",
       "1599974    Kristah_Diggs  @yrclndstnlvr ahaha nooo you were just away fr...  \n",
       "1599975        CoachChic  @BizCoachDeb  Hey, I'm baack! And, thanks so m...  \n",
       "1599976         serianna  @mattycus Yeah, my conscience would be clear i...  \n",
       "1599977   TeamUKskyvixen  @MayorDorisWolfe Thats my girl - dishing out t...  \n",
       "1599978      LaurenMoo10                          @shebbs123 i second that   \n",
       "1599979    angel_sammy04                                     In the garden   \n",
       "1599980        puchal_ek  @myheartandmind jo jen by nemuselo zrovna tÃ© ...  \n",
       "1599981    youtubelatest  Another Commenting Contest! [;: Yay!!!  http:/...  \n",
       "1599982  Mandi_Davenport  @thrillmesoon i figured out how to see my twee...  \n",
       "1599983         xoAurixo  @oxhot theri tomorrow, drinking coffee, talkin...  \n",
       "1599984       RobFoxKerr  You heard it here first -- We're having a girl...  \n",
       "1599985         LISKFEST  if ur the lead singer in a band, beware fallin...  \n",
       "1599986          marhgil              @tarayqueen too much ads on my blog.   \n",
       "1599987        cathriiin  @La_r_a NEVEER  I think that you both will get...  \n",
       "1599988          tellman  @Roy_Everitt ha- good job. that's right - we g...  \n",
       "1599989        jazzstixx                 @Ms_Hip_Hop im glad ur doing well   \n",
       "1599990    razzberry5594                              WOOOOO! Xbox is back   \n",
       "1599991        AgustinaP  @rmedina @LaTati Mmmm  That sounds absolutely ...  \n",
       "1599992    sdancingsteph                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd   \n",
       "1599993      ChloeAmisha                                  @SCOOBY_GRITBOYS   \n",
       "1599994        EvolveTom  @Cliff_Forster Yeah, that does work better tha...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = \"ISO-8859-1\",header=None)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  5\n",
       "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  0  is upset that he can't update his Facebook by ...\n",
       "2  0  @Kenichan I dived many times for the ball. Man...\n",
       "3  0    my whole body feels itchy and like its on fire \n",
       "4  0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([1,2,3,4],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[0]\n",
    "x=df[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "X_ngrams = vectorizer.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ngrams,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "clf = svm.LinearSVC(loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8056051925403287\n",
      "0.7985568020566207\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, y_pred, pos_label=0))\n",
    "print(metrics.f1_score(y_test, y_pred, pos_label=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy =  0.80214375\n",
      "training set accuracy =  0.854765625\n"
     ]
    }
   ],
   "source": [
    "print('test set accuracy = ',clf.score(X_test, y_test))\n",
    "print('training set accuracy = ',clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 588461)\t0.3847820406134551\n",
      "  (0, 282902)\t0.13325466639021682\n",
      "  (0, 627235)\t0.1727585123147094\n",
      "  (0, 155155)\t0.14322600378491926\n",
      "  (0, 12898)\t0.4711174549706515\n",
      "  (0, 86741)\t0.21482894077478346\n",
      "  (0, 600330)\t0.10767422927134272\n",
      "  (0, 123107)\t0.25645368289347503\n",
      "  (0, 675497)\t0.09293595022467749\n",
      "  (0, 552090)\t0.30355162901739546\n",
      "  (0, 256817)\t0.13857788944011265\n",
      "  (0, 176163)\t0.24261904027026174\n",
      "  (0, 132252)\t0.35162019379011117\n",
      "  (0, 458032)\t0.10459526434807508\n",
      "  (0, 607609)\t0.27641559689924305\n",
      "  (0, 177229)\t0.12809105297140524\n",
      "  (0, 613861)\t0.07264838063771703\n",
      "  (0, 192926)\t0.13643455387258877\n",
      "  (0, 300094)\t0.09072433436573028\n",
      "  (1, 600330)\t0.1266677119840868\n",
      "  (1, 300094)\t0.10672789518118093\n",
      "  (1, 299013)\t0.11319087135196068\n",
      "  (1, 635099)\t0.280423124045034\n",
      "  (1, 270301)\t0.1853243765194385\n",
      "  (1, 128986)\t0.14739911518782142\n",
      "  :\t:\n",
      "  (1599997, 402259)\t0.15291998788416442\n",
      "  (1599997, 675991)\t0.19572962503227642\n",
      "  (1599997, 77204)\t0.18640791355413427\n",
      "  (1599997, 507917)\t0.26421689680375926\n",
      "  (1599997, 81547)\t0.32446169736687597\n",
      "  (1599997, 184363)\t0.39797311630527454\n",
      "  (1599997, 421266)\t0.4846732933109769\n",
      "  (1599997, 389758)\t0.4880439984583832\n",
      "  (1599998, 458032)\t0.10762431847372347\n",
      "  (1599998, 613861)\t0.07475226056444147\n",
      "  (1599998, 433663)\t0.0908238076013291\n",
      "  (1599998, 611054)\t0.14458712676985783\n",
      "  (1599998, 267348)\t0.1699918438300263\n",
      "  (1599998, 111982)\t0.224533970663405\n",
      "  (1599998, 105306)\t0.20233726078132785\n",
      "  (1599998, 624222)\t0.37527265050007613\n",
      "  (1599998, 62429)\t0.32999774429182194\n",
      "  (1599998, 14304)\t0.41176873535953046\n",
      "  (1599998, 545787)\t0.4482648202189847\n",
      "  (1599998, 65231)\t0.46173443925174057\n",
      "  (1599999, 267348)\t0.1815355381302975\n",
      "  (1599999, 139203)\t0.4216087745738827\n",
      "  (1599999, 604623)\t0.5032954246556091\n",
      "  (1599999, 568573)\t0.5176797297165412\n",
      "  (1599999, 568868)\t0.5176797297165412\n"
     ]
    }
   ],
   "source": [
    "print(X_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  5\n",
       "0  0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  0  is upset that he can't update his Facebook by ...\n",
       "2  0  @Kenichan I dived many times for the ball. Man...\n",
       "3  0    my whole body feels itchy and like its on fire \n",
       "4  0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = \"ISO-8859-1\",header=None)\n",
    "df.drop([1,2,3,4],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[0]\n",
    "x=df[5]\n",
    "raw_text = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace email, URLs, money, phone no. , numbers, collapse all kind of white spaces into single space, convert in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text):\n",
    "    processed = raw_text.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b',\n",
    "                                     'emailaddr')\n",
    "    processed = processed.str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)',\n",
    "                                      'httpaddr')\n",
    "    processed = processed.str.replace(r'£|\\$', 'moneysymb')    \n",
    "    processed = processed.str.replace(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr')    \n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "    processed = processed.str.lower()\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWordsRemovar(processed):\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in set(stop_words)))\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemme(processed):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    processed = processed.apply(lambda x: ' '.join(\n",
    "    porter.stem(term) for term in x.split()))\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_preprocess = preprocess(raw_text)\n",
    "after_stop_words_removal = stopWordsRemovar(after_preprocess)\n",
    "processed = after_stop_words_removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          switchfoot httpaddr awww bummer shoulda got da...\n",
       "1          upset update facebook texting might cry result...\n",
       "2          kenichan dived many times ball managed save nu...\n",
       "3                           whole body feels itchy like fire\n",
       "4                           nationwideclass behaving mad see\n",
       "5                                        kwesidei whole crew\n",
       "6                                                   need hug\n",
       "7          loltrish hey long time see yes rains bit bit l...\n",
       "8                                             tatiana_k nope\n",
       "9                                         twittera que muera\n",
       "10                           spring break plain city snowing\n",
       "11                                              pierced ears\n",
       "12         caregiving bear watch thought ua loss embarras...\n",
       "13         octolinznumbr counts idk either never talk any...\n",
       "14         smarrison would first gun really though zac sn...\n",
       "15         iamjazzyfizzle wish got watch miss iamlilnicki...\n",
       "16         hollis death scene hurt severely watch film wr...\n",
       "17                                                file taxes\n",
       "18         lettya ahh ive always wanted see rent love sou...\n",
       "19         fakerpattypattz oh dear drinking forgotten tab...\n",
       "20                              alydesigns day get much done\n",
       "21         one friend called asked meet mid valley today ...\n",
       "22                             angry_barista baked cake ated\n",
       "23                                          week going hoped\n",
       "24                                blagh class numbr tomorrow\n",
       "25                                     hate call wake people\n",
       "26                           going cry sleep watching marley\n",
       "27                                           im sad httpaddr\n",
       "28                        ooooh lol leslie ok leslie get mad\n",
       "29         meh almost lover exception track gets depresse...\n",
       "                                 ...                        \n",
       "1599970       thanks eastwestchic amp wangyip thanks looking\n",
       "1599971           marttn thanks martin imaginative interface\n",
       "1599972                  mikejonesphoto congrats mike way go\n",
       "1599973                httpaddr omg office space wanna steal\n",
       "1599974    yrclndstnlvr ahaha nooo away everyone else see...\n",
       "1599975    bizcoachdeb hey baack thanks much kind notes g...\n",
       "1599976            mattycus yeah conscience would clear case\n",
       "1599977    mayordoriswolfe thats girl dishing quot advice...\n",
       "1599978                                   shebbsnumbr second\n",
       "1599979                                               garden\n",
       "1599980    myheartandmind jo jen nemuselo zrovna tã holce...\n",
       "1599981              another commenting contest yay httpaddr\n",
       "1599982    thrillmesoon figured see tweets facebook statu...\n",
       "1599983    oxhot theri tomorrow drinking coffee talking i...\n",
       "1599984    heard first girl hope looks wendy brains kiddi...\n",
       "1599985    ur lead singer band beware falling prey lsd qu...\n",
       "1599986                             tarayqueen much ads blog\n",
       "1599987                         la_r_a neveer think get well\n",
       "1599988    roy_everitt ha good job right gotta throw bigr...\n",
       "1599989                           ms_hip_hop im glad ur well\n",
       "1599990                                     wooooo xbox back\n",
       "1599991    rmedina latati mmmm sounds absolutely perfect ...\n",
       "1599992                              recovering long weekend\n",
       "1599993                                      scooby_gritboys\n",
       "1599994    cliff_forster yeah work better waiting end won...\n",
       "1599995                        woke school best feeling ever\n",
       "1599996    httpaddr cool hear old walt interviews â httpaddr\n",
       "1599997                      ready mojo makeover ask details\n",
       "1599998    happy numbrth birthday boo alll time tupac ama...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: 5, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "X_ngrams = vectorizer.fit_transform(processed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ngrams,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "clf = svm.LinearSVC(loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822362908481519\n",
      "0.7791799099977971\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, y_pred, pos_label=0))\n",
    "print(metrics.f1_score(y_test, y_pred, pos_label=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy =  0.78071875\n",
      "training set accuracy =  0.84261796875\n"
     ]
    }
   ],
   "source": [
    "print('test set accuracy = ',clf.score(X_test, y_test))\n",
    "print('training set accuracy = ',clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = \"ISO-8859-1\",header=None)\n",
    "df.drop([1,2,3,4],axis=1,inplace=True)\n",
    "y=df[0]\n",
    "x=df[5]\n",
    "raw_text = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after_preprocess = preprocess(raw_text)\n",
    "#after_stop_words_removal = stopWordsRemovar(after_preprocess)\n",
    "#processed = after_stop_words_removal\n",
    "processed = raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "X_ngrams = vectorizer.fit_transform(processed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ngrams,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANIKET RAJ\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBClassifier()\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6697055570915124\n",
      "0.7274298425735798\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, y_pred, pos_label=0))\n",
    "print(metrics.f1_score(y_test, y_pred, pos_label=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70133125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
